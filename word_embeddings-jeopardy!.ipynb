{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NLP - Word Embeddings\n",
    "\n",
    "Think back to NLP as we've understood it so far.\n",
    "\n",
    "If we've had some luck with NLP modeling, likely with a NaiveBayes algorithm, we were able to illustrate some correlations between words and some other feature of interest.\n",
    "\n",
    "But to whatever extent that our models were able to make connections and pick up on correlations, they did this *without any understanding of the **meaning** of the words in question*.\n",
    "\n",
    "Let's think for a minute about words and objective meanings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sense of meaning for computational purposes by thinking about meaning in terms of similarity, i.e. thinking about meaning *holistically*.\n",
    "\n",
    "Q. Is there any precedent for this way of thinking about meaning? <br/>\n",
    "A. [Yes](https://plato.stanford.edu/entries/meaning-holism/#ArgForMeaHol)\n",
    "\n",
    "So what will this look like for us?\n",
    "\n",
    "*Remember cosine similarity?*\n",
    "\n",
    "$\\rightarrow$We'll have much the same idea here: Associate each word with values along particular dimensions in a multi-dimensional space. If we had a dimension for *softness*, for example, then pillows and marshmallows would score higher on it than rocks and bricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Gensim? See [here](https://en.wikipedia.org/wiki/Gensim) and [here](https://radimrehurek.com/gensim/). But, basically, gensim is a package with lots of topic-modeling and NLP tools, inlcuding Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the data [here!](https://drive.google.com/file/d/0BwT5wj_P7BKXb2hfM3d2RHU1ckE/view) (Just click 'Download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "\n",
    "import json\n",
    "\n",
    "with open('JEOPARDY_QUESTIONS1.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216930"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'HISTORY',\n",
       " 'air_date': '2004-12-31',\n",
       " 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\",\n",
       " 'value': '$200',\n",
       " 'answer': 'Copernicus',\n",
       " 'round': 'Jeopardy!',\n",
       " 'show_number': '4680'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first element in our list\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have?\n",
    "\n",
    "len(data[0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'For\",\n",
       " 'the',\n",
       " 'last',\n",
       " '8',\n",
       " 'years',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life,',\n",
       " 'Galileo',\n",
       " 'was',\n",
       " 'under',\n",
       " 'house',\n",
       " 'arrest',\n",
       " 'for',\n",
       " 'espousing',\n",
       " 'this',\n",
       " \"man's\",\n",
       " \"theory'\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try that again!\n",
    "\n",
    "data[0]['question'].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0]['question'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3169994"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 0\n",
    "for clue in data:\n",
    "    length += len(clue['question'].split(' '))\n",
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec requires that our text have the form of a list\n",
    "# of 'sentences', where each sentence is itself a list of\n",
    "# words. How can we put our _Jeopardy!_ clues in that shape?\n",
    "\n",
    "import string\n",
    "text = []\n",
    "\n",
    "for clue in data:\n",
    "    sentence = clue['question'].translate(str.maketrans('', '',\n",
    "                                                        string.punctuation)).split(' ')\n",
    "    \n",
    "    new_sent = []\n",
    "    for word in sentence:\n",
    "        new_sent.append(word.lower())\n",
    "    \n",
    "    text.append(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'the',\n",
       " 'last',\n",
       " '8',\n",
       " 'years',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life',\n",
       " 'galileo',\n",
       " 'was',\n",
       " 'under',\n",
       " 'house',\n",
       " 'arrest',\n",
       " 'for',\n",
       " 'espousing',\n",
       " 'this',\n",
       " 'mans',\n",
       " 'theory']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the new structure of our first clue\n",
    "\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the model is simply a matter of\n",
    "# instantiating a Word2Vec object.\n",
    "\n",
    "model = gensim.models.Word2Vec(text, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Bag of Words vs. Skipgram\n",
    "\n",
    "<a href=\"https://www.researchgate.net/figure/Illustration-of-the-Skip-gram-and-Continuous-Bag-of-Word-CBOW-models_fig1_281812760\"><img src=\"https://www.researchgate.net/profile/Wang_Ling/publication/281812760/figure/fig1/AS:613966665486361@1523392468791/Illustration-of-the-Skip-gram-and-Continuous-Bag-of-Word-CBOW-models.png\" alt=\"Illustration of the Skip-gram and Continuous Bag-of-Word (CBOW) models.\"/></a>\n",
    "\n",
    "[More on Skipgram](https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11335284, 15849970)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To train, call 'train()'!\n",
    "\n",
    "model.train(text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3169994"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking word count\n",
    "\n",
    "model.corpus_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/cnuno/anaconda3/envs/dl-env:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "gensim                    3.8.0            py37h6440ff4_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1a398cded0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The '.wv' attribute stores the word vectors\n",
    "\n",
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41389152, -0.21379645, -0.05707829, -0.07153194,  0.2547051 ,\n",
       "       -0.22398384, -0.32318044, -0.29879382,  0.06783722,  0.16170059,\n",
       "       -0.27415675,  0.27535692,  0.09744826, -0.27821708,  0.10194746,\n",
       "       -0.087114  , -0.18206966,  0.07170312, -0.221     ,  0.24115247,\n",
       "        0.61907536,  0.39009655, -0.08618946, -0.3570007 , -0.43365076,\n",
       "       -0.11205005, -0.19586013, -0.17298093,  0.13166846,  0.14149003,\n",
       "        0.33901733,  0.17434967, -0.11049028,  0.4116068 ,  1.0272555 ,\n",
       "       -0.23351939, -0.17182012, -0.08514057,  0.05082391, -0.00279134,\n",
       "        0.02326906,  0.2784366 ,  0.28213766,  0.22667737,  0.05913717,\n",
       "        0.05059214, -0.16128449,  0.7684499 , -0.00563918, -0.26297987,\n",
       "        0.02033165, -0.36268723,  1.0993304 ,  0.08952368,  0.25243783,\n",
       "       -0.24234952,  0.27081093,  0.01740484,  0.36989826, -0.10387513,\n",
       "        0.10065239,  0.5481624 ,  0.2829658 , -0.3862849 ,  0.038257  ,\n",
       "       -0.35590202,  0.26815838, -0.26363346, -0.46965846,  0.1222413 ,\n",
       "       -0.01063839, -0.39335778,  0.42947426,  0.44090298,  0.6041869 ,\n",
       "        0.12259459,  0.14228882,  0.10487564,  0.3153987 ,  0.32398945,\n",
       "       -0.0246874 ,  0.12944692,  0.1131522 , -0.23017077,  0.22696379,\n",
       "        0.6191573 ,  0.4564308 ,  0.12089231, -0.0581337 ,  0.42815393,\n",
       "        0.1094252 , -0.13290332,  0.54038286, -0.1604433 ,  0.25651878,\n",
       "        0.54129064,  0.06219624, -0.3327607 , -0.12932552, -0.2169408 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The vectors are keyed by the words\n",
    "\n",
    "model.wv['child']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26434654, -0.05182785, -0.09964533,  0.13291237,  0.22911415,\n",
       "        0.21761477, -0.04358964, -0.0626228 ,  0.19776426, -0.19352308,\n",
       "       -0.15804824,  0.09418879,  0.382234  , -0.6589204 ,  0.08990534,\n",
       "       -0.0223011 , -0.50250673, -0.0517229 , -0.14673188,  0.2079221 ,\n",
       "       -0.42906132, -0.1085382 , -0.10119518, -0.10167561, -0.4345436 ,\n",
       "        0.00389919,  0.1139966 ,  0.3975856 ,  0.28031906,  0.2614984 ,\n",
       "       -0.06797682,  0.10466772, -0.15503952,  0.2754476 ,  0.36045685,\n",
       "       -0.68615896, -0.05450634, -0.40025368,  0.2632229 , -0.00203091,\n",
       "       -0.04085897,  0.00126617, -0.31169242,  0.41204926,  0.6382078 ,\n",
       "       -0.1368308 , -0.11402565,  0.3641616 ,  0.15780643, -0.12872322,\n",
       "       -0.2568089 , -0.21986516,  0.50133044,  0.354717  ,  0.03761978,\n",
       "       -0.03058056,  0.4780767 ,  0.03866231, -0.34741688,  0.27295163,\n",
       "        0.1805314 ,  0.81815976,  0.19554392,  0.12015846, -0.1981677 ,\n",
       "       -0.23946868, -0.09422665,  0.06651907, -0.12793902, -0.09593833,\n",
       "       -0.08470441, -0.3281513 ,  0.61098325,  0.03378816,  0.22524229,\n",
       "       -0.01863274,  0.45705417, -0.4002573 , -0.06193798,  0.46762818,\n",
       "       -0.01591303, -0.07351214, -0.23810029, -0.16141708,  0.5105797 ,\n",
       "        0.01092202,  0.3443475 ,  0.11236721, -0.04094106,  0.09544317,\n",
       "        0.11822894,  0.23252992,  0.15745533, -0.40271157,  0.22433361,\n",
       "        0.49810702,  0.04708994, -0.76269054, -0.10678917, -0.14958328],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"life\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.wv methods\n",
    "#### 'most_similar()' and 'similarity()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chippendale', 0.7063581943511963),\n",
       " ('paints', 0.6946310997009277),\n",
       " ('monogram', 0.6937282681465149),\n",
       " ('wearers', 0.691198468208313),\n",
       " ('cabriole', 0.6908915638923645),\n",
       " ('ceramic', 0.6891263723373413),\n",
       " ('pottery', 0.6886754035949707),\n",
       " ('jewelry', 0.679322361946106),\n",
       " ('linen', 0.676114559173584),\n",
       " ('neoclassical', 0.6741198301315308)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('furniture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67932236"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('furniture', 'jewelry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rodent', 0.7958711981773376),\n",
       " ('carnivore', 0.792759358882904),\n",
       " ('flightless', 0.7791604995727539),\n",
       " ('shorttailed', 0.7768223285675049),\n",
       " ('parrot', 0.7767276763916016),\n",
       " ('feline', 0.7731635570526123),\n",
       " ('reptile', 0.7716844081878662),\n",
       " ('seabird', 0.7708951234817505),\n",
       " ('marsupial', 0.7704271078109741),\n",
       " ('wading', 0.7702571153640747)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['cat', 'animal', 'pet', 'mammal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following 'equations':\n",
    "\n",
    "King + Woman - Man = x\n",
    "\n",
    "Brother + Woman - Man = y\n",
    "\n",
    "What values would you suggest for x and y here?\n",
    "\n",
    "Clearly, getting good answers to these equations depends on understanding the *meanings* of the underlying words.\n",
    "\n",
    "Or does it? The `most_similar()` method takes a 'negative' parameter as well as a 'positive' one, so we can consult our trained word vectors to see how they would answer these questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('insect', 0.38763338327407837),\n",
       " ('lizard', 0.3715643882751465),\n",
       " ('breed', 0.36911389231681824),\n",
       " ('camel', 0.3445417881011963),\n",
       " ('domesticated', 0.344135582447052),\n",
       " ('dog', 0.3417161703109741),\n",
       " ('sheep', 0.338253915309906),\n",
       " ('horse', 0.33783453702926636),\n",
       " ('rodent', 0.33757859468460083),\n",
       " ('parrot', 0.3291858434677124)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['cat', 'animal'], negative='pet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('throne', 0.31816551089286804),\n",
       " ('reign', 0.3027268052101135),\n",
       " ('monarch', 0.285883367061615),\n",
       " ('queen', 0.2575371563434601),\n",
       " ('princess', 0.25350421667099),\n",
       " ('borgia', 0.2443619668483734),\n",
       " ('athena', 0.2381279021501541),\n",
       " ('empress', 0.2355743795633316),\n",
       " ('ferdinand', 0.23263314366340637),\n",
       " ('isabella', 0.23086723685264587)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['king', 'woman'], negative='man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('retitled', 0.613320529460907),\n",
       " ('reruns', 0.5960466861724854),\n",
       " ('310', 0.5951439738273621),\n",
       " ('purchasing', 0.5930753946304321),\n",
       " ('surfin', 0.5921533703804016),\n",
       " ('opryland', 0.5888020396232605),\n",
       " ('fargo', 0.5876047611236572),\n",
       " ('tyra', 0.586865246295929),\n",
       " ('npr', 0.5865541696548462),\n",
       " ('pageant', 0.5837612152099609)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('zambia', 0.7140920162200928),\n",
       " ('commonwealth', 0.7063342332839966),\n",
       " ('marianas', 0.6701198816299438),\n",
       " ('turkmenistan', 0.6647850275039673),\n",
       " ('zimbabwe', 0.6581022143363953),\n",
       " ('1531', 0.6577807068824768),\n",
       " ('everglades', 0.6545292139053345),\n",
       " ('somalia', 0.6537880301475525),\n",
       " ('48th', 0.6531057357788086),\n",
       " ('clashes', 0.6496423482894897)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shakespeares', 0.7484585642814636),\n",
       " ('sophocles', 0.7384794354438782),\n",
       " ('euripides', 0.7194842100143433),\n",
       " ('romeo', 0.694046139717102),\n",
       " ('ibsen', 0.6867465376853943),\n",
       " ('hamlet', 0.686214029788971),\n",
       " ('falstaff', 0.6801735162734985),\n",
       " ('rur', 0.6699120998382568),\n",
       " ('shakespearean', 0.6686151027679443),\n",
       " ('shaws', 0.658797562122345)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kinnear', 0.8203802704811096),\n",
       " ('bebe', 0.8153233528137207),\n",
       " ('abduljabbar', 0.8128387331962585),\n",
       " ('walston', 0.8038377165794373),\n",
       " ('michaels', 0.7981163859367371),\n",
       " ('waterstona', 0.7931976914405823),\n",
       " ('cheech', 0.7915717959403992),\n",
       " ('hamlisch', 0.789059042930603),\n",
       " ('carradine', 0.7878305912017822),\n",
       " ('navratilova', 0.7842996120452881)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('greg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quincy', 0.6975979804992676),\n",
       " ('prescott', 0.6886768341064453),\n",
       " ('madison', 0.6822203993797302),\n",
       " ('jeffersons', 0.6721287369728088),\n",
       " ('wheeler', 0.6562268733978271),\n",
       " ('tilden', 0.653816282749176),\n",
       " ('vacated', 0.6519813537597656),\n",
       " ('taney', 0.6515076160430908),\n",
       " ('dodd', 0.6510909795761108),\n",
       " ('abe', 0.6507692337036133)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('jefferson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dc', 0.7961041331291199),\n",
       " ('dcs', 0.6513048410415649),\n",
       " ('arlington', 0.6474683284759521),\n",
       " ('abilene', 0.6439856290817261),\n",
       " ('washingtons', 0.6427392959594727),\n",
       " ('p3', 0.6360026001930237),\n",
       " ('newseum', 0.629417896270752),\n",
       " ('dca', 0.6268893480300903),\n",
       " ('baylor', 0.6248763203620911),\n",
       " ('hw', 0.6241251826286316)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('washington')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emperors', 0.27023375034332275),\n",
       " ('russia', 0.2081650346517563),\n",
       " ('dictator', 0.20734745264053345),\n",
       " ('regime', 0.2018895000219345),\n",
       " ('nazi', 0.1908772587776184),\n",
       " ('reign', 0.18869484961032867),\n",
       " ('conquered', 0.1868910789489746),\n",
       " ('invaded', 0.18686148524284363),\n",
       " ('ussr', 0.1859874725341797),\n",
       " ('shah', 0.18590399622917175)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['president', 'germany'], negative='usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emperors', 0.2552731931209564),\n",
       " ('germany', 0.23988507688045502),\n",
       " ('reign', 0.23693090677261353),\n",
       " ('shah', 0.22766581177711487),\n",
       " ('russia', 0.2172096073627472),\n",
       " ('czar', 0.21056053042411804),\n",
       " ('conquest', 0.20255963504314423),\n",
       " ('dictator', 0.19438612461090088),\n",
       " ('regime', 0.19192437827587128),\n",
       " ('versailles', 0.19070853292942047)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['president', 'france'], negative='usa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'doesnt_match()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnuno/anaconda3/envs/dl-env/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['breakfast', 'lunch', 'frog', 'food'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnuno/anaconda3/envs/dl-env/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'this'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['lunch', 'this'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bush'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['tree', 'flower', 'bush', 'plant', 'toothbrush'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toothbrush'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['tree', 'flower', 'plant', 'toothbrush'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'closer_than()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prince',\n",
       " 'emperor',\n",
       " 'kings',\n",
       " 'iii',\n",
       " 'throne',\n",
       " 'ruler',\n",
       " 'iv',\n",
       " 'viii',\n",
       " 'vi',\n",
       " 'vii',\n",
       " 'tudor',\n",
       " 'constantine',\n",
       " 'ix',\n",
       " 'leopold',\n",
       " 'xiii',\n",
       " 'charlemagne',\n",
       " 'darius',\n",
       " 'haakon',\n",
       " 'consort',\n",
       " 'rama',\n",
       " 'xii',\n",
       " 'olaf',\n",
       " 'umberto',\n",
       " 'nebuchadnezzar',\n",
       " 'courtier',\n",
       " 'menelik',\n",
       " 'boleslaw',\n",
       " 'geats',\n",
       " 'canute',\n",
       " 'ethelred']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which words are closer to 'king' than 'queen' is?\n",
    "\n",
    "model.wv.closer_than('king', 'queen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'distance()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this it will make more sense to\n",
    "# normalize our vectors.\n",
    "\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('king', 'king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49094682931900024"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('joy', 'happiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'evaluate_word_analogies()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `evaluate_word_analogies()` method takes in a string of quadruples, properly formatted (see [here](https://radimrehurek.com/gensim/models/keyedvectors.html)), and returns a list of dictionaries. Each dictionary has two keys: 'correct' and 'incorrect', the values for which are lists of the analogies that the model correctly or incorrectly predicted.\n",
    "\n",
    "Check out [this text file](https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-24 11:03:26--  https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.192.133, 151.101.0.133, 151.101.64.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.192.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 603955 (590K) [text/plain]\n",
      "Saving to: ‘questions-words.txt’\n",
      "\n",
      "questions-words.txt 100%[===================>] 589.80K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-10-24 11:03:26 (4.35 MB/s) - ‘questions-words.txt’ saved [603955/603955]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatives = model.wv.evaluate_word_analogies(\"questions-words.txt\")[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relatives['correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relatives['incorrect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BOY', 'GIRL', 'BROTHER', 'SISTER'),\n",
       " ('BOY', 'GIRL', 'BROTHERS', 'SISTERS'),\n",
       " ('BOY', 'GIRL', 'FATHER', 'MOTHER'),\n",
       " ('BOY', 'GIRL', 'GRANDSON', 'GRANDDAUGHTER'),\n",
       " ('BOY', 'GIRL', 'HE', 'SHE')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatives['correct'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BOY', 'GIRL', 'DAD', 'MOM'),\n",
       " ('BOY', 'GIRL', 'GRANDFATHER', 'GRANDMOTHER'),\n",
       " ('BOY', 'GIRL', 'GRANDPA', 'GRANDMA'),\n",
       " ('BOY', 'GIRL', 'GROOM', 'BRIDE'),\n",
       " ('BOY', 'GIRL', 'HUSBAND', 'WIFE')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatives['incorrect'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
